---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "News Archive"
subtitle: ""
summary: ""
authors: []
tags: []
categories: []
date: 2022-01-11T09:38:15+11:00
lastmod: 2022-01-11T09:38:15+11:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---

- (Mar-25) Our paper  [*Bilevel Learning with Inexact Stochastic Gradients*](https://arxiv.org/abs/2412.12049) with [Mohammad Sadegh Salehi](https://mohammadsadeghsalehi.github.io/), [Matthias Ehrhardt](https://mehrhardt.github.io/) (University of Bath) and [Subhadip Mukherjee](https://sites.google.com/view/subhadip-mukherjee/home) (IIT Kharagpur) has been accepted to [SSVM 2025](https://sites.google.com/view/ssvm-2025/home-page).
- (Mar-25) Our paper [*High-resolution x-ray scanning with a diffuse, Huffman-patterned probe to reduce radiation damage*](https://doi.org/10.1107/S1600577525002127) with [Alaleh Aminzadeh](https://physics.anu.edu.au/contact/people/profile.php?ID=2927) and [Andrew Kingston](https://physics.anu.edu.au/contact/people/profile.php?ID=67) (ANU), and
[David Paganin](https://www.monash.edu/science/schools/physics/research/research-areas?a=64532), [Tim Petersen](https://research.monash.edu/en/persons/timothy-petersen) and [Imants Svalbe](https://monash.academia.edu/ImantsSvalbe) (Monash University) has been accepted to the Journal of Synchrotron Radiation.
- (Feb-25) I am now an Associate Investigator for [OPTIMA](https://optima.org.au/), an ARC Industrial Transformation Training Centre focused on optimisation and operations research. 
- (Feb-25) I received a 2024 meritorious service award for the journal *Mathematical Programming*, given by the editorial board to "the referees who have demonstrated exceptional diligence in their service to the journal".
- (Jan-25) Milestone reached! My open-source Python software packages have been installed over 1 million times from PyPI, according to [pepy.tech](https://pepy.tech/). The most popular packages are [Py-BOBYQA](https://github.com/numericalalgorithmsgroup/pybobyqa/), [DFO-LS](https://github.com/numericalalgorithmsgroup/dfols) and [directsearch](https://github.com/lindonroberts/directsearch). 
- (Jan-25) My paper [*Model Construction for Convex-Constrained Derivative-Free Optimization*](https://doi.org/10.1137/24M1649113) has been accepted by SIAM Journal on Optimization.
- (Jan-25) New paper [*Projected proximal gradient trust-region algorithm for nonsmooth optimization*](https://arxiv.org/abs/2501.04889) with [Minh Dao](https://sites.google.com/site/daonminh/) (RMIT University) and [Hung Phan](https://faculty.uml.edu/hung_phan/) (University of Massachusetts Lowell). We develop some new worst-case complexity theory and novel subproblem solver for trust-region methods with nonsmooth regularizers.
- (Dec-24) New paper [*Randomized Subspace Derivative-Free Optimization with Quadratic Models and Second-Order Convergence*](https://arxiv.org/abs/2412.14431) with [Coralia Cartis](http://people.maths.ox.ac.uk/cartis/) (University of Oxford). We extend the theory of random subspace derivative-free optimization to include second-order complexity and develop a practical algorithm based on quadratic interpolation models.
- (Dec-24) New paper [*Bilevel Learning with Inexact Stochastic Gradients*](https://arxiv.org/abs/2412.12049) with [Mohammad Sadegh Salehi](https://mohammadsadeghsalehi.github.io/), [Matthias Ehrhardt](https://mehrhardt.github.io/) (University of Bath) and [Subhadip Mukherjee](https://sites.google.com/view/subhadip-mukherjee/home) (IIT Kharagpur). We show how the theory of biased SGD can be applied to bilevel learning with inexact hypergradients.
- (Dec-24) I will be presenting on [convex-constrained derivative-free optimization](https://arxiv.org/abs/2403.14960) at [WOMBAT 2024](https://wombat.mocao.org/) and [adaptive bilevel learning](https://arxiv.org/abs/2308.10098) at the [Sydney Workshop on the Mathematics of Data Science](https://www.maths.usyd.edu.au/u/USYD-MDSworkshop/), both running at the University of Sydney.
- (Nov-24) Excited to receive an Australian Research Council [Discovery Project 2025](https://www.arc.gov.au/funding-research/grant-announcement-kits/discovery-projects-2025) grant for the project *Next Generation Newton-type Methods with Minimum Residual Solver*, with [Fred Roosta](https://people.smp.uq.edu.au/FredRoosta/) (University of Queensland), [Andre Milzarek](https://sds.cuhk.edu.cn/en/teacher/64) (Chinese University of Hong Kong, Shenzhen) and [Steve Wright](https://wrightstephen.github.io/sw_proj/) (University of Wisconsin-Madison).
- (Oct-24) New paper [*High-resolution x-ray scanning with a diffuse, Huffman-patterned probe to minimise radiation damage*](https://arxiv.org/abs/2410.18348) with [Alaleh Aminzadeh](https://physics.anu.edu.au/contact/people/profile.php?ID=2927) and [Andrew Kingston](https://physics.anu.edu.au/contact/people/profile.php?ID=67) (ANU), and
[David Paganin](https://www.monash.edu/science/schools/physics/research/research-areas?a=64532), [Tim Petersen](https://research.monash.edu/en/persons/timothy-petersen) and [Imants Svalbe](https://monash.academia.edu/ImantsSvalbe)  (Monash University). We demonstrate how to computationally construct aperiodic masks for ghost imaging and show their practical experimental performance.
- (Sep-24) I will be talking about randomized subspace derivative-free optimization algorithms at the [UNSW Applied Mathematics Seminar](https://www.unsw.edu.au/science/our-schools/maths/engage-with-us/seminars/2024/Randomised-Subspace-Methods-for-Scalable-Derivative-Free-Optimisation). 
- (Aug-24) Our paper [*Expected decrease for derivative-free algorithms using random subspaces*](https://doi.org/10.1090/mcom/4011) with [Warren Hare](https://cmps.ok.ubc.ca/about/contact/warren-hare/) (University of British Columbia) and [Clément Royer](https://www.lamsade.dauphine.fr/~croyer/) (Université Paris Dauphine-PSL) has been accepted by Mathematics of Computation.
- (Jul-24) New paper [*Black-box Optimization Algorithms for Regularized Least-squares Problems*](https://arxiv.org/abs/2407.14915) with [Yanjun Liu](https://yanjunliu-regina.github.io/) (Princeton University) and Kevin Lam (Australian National University). We introduce a DFO method for nonlinear least-squares problems with nonsmooth regularizers.
- (Jun-24) I will be visiting [Clément Royer](https://www.lamsade.dauphine.fr/~croyer/) at the Université Paris Dauphine-PSL and then attending the [2nd Derivative-Free Optimization Symposium](https://sites.google.com/diag.uniroma1.it/dfos24/home) at the University of Padova.
- (May-24) I will be hosting [Hung Phan](https://faculty.uml.edu/hung_phan/) (University of Massachusetts Lowell) as part of [SMRI's](https://mathematical-research-institute.sydney.edu.au/) International Visitor Program.
- (Apr-24) Significant new revisions to an earlier preprint, now titled [*An adaptively inexact first-order method for bilevel optimization with application to hyperparameter learning*](https://arxiv.org/abs/2308.10098), are now available. This is joint work with [Mohammad Sadegh Salehi](https://mohammadsadeghsalehi.github.io/), [Matthias Ehrhardt](https://mehrhardt.github.io/) (University of Bath) and [Subhadip Mukherjee](https://sites.google.com/view/subhadip-mukherjee/home) (IIT Kharagpur).
- (Mar-24) New paper [*Model Construction for Convex-Constrained Derivative-Free Optimization*](https://arxiv.org/abs/2403.14960). This develops an approximation theory for quadratic interpolation in general convex-constrained sets, extending [earlier work on linear interpolation](https://doi.org/10.1137/21M1460971). 
- (Feb-24) Hosted [Shane Henderson](https://people.orie.cornell.edu/shane/) (Cornell University) as part of [SMRI's](https://mathematical-research-institute.sydney.edu.au/) International Visitor Program.
- (Feb-24) Our paper [*Non-Uniform Smoothness for Gradient Descent*](https://openreview.net/pdf?id=17ESEjETbP) with [Albert Berahas](https://aberahas.engin.umich.edu/) (University of Michigan) and [Fred Roosta](https://people.smp.uq.edu.au/FredRoosta/) (University of Queensland) has been accepted by Transactions on Machine Learning Research.
- (Feb-24) I will be speaking about the paper [*Dynamic Bilevel Learning with Inexact Line Search*](https://arxiv.org/abs/2308.10098) as an invited speaker for the first [SigmaOpt workshop](https://www.mathematics.org.au/sys/pages/plain.php?page_id=25&conf_id=61).
- (Jan-24) Happy to receive a [CNRS International Emerging Actions](https://international.cnrs.fr/en/actualite/appel-iea-2023/) grant with [Clément Royer](https://www.lamsade.dauphine.fr/~croyer/) (Université Paris Dauphine-PSL) to work on random subspace methods for DFO.
- (Dec-23) I am a co-organiser of the joint [WOMBAT/WICO workshops](https://wombat.mocao.org/) on optimisation and computational maths, 11-15 December at the University of Sydney. I am also speaking about [expected decrease analysis for random subspace methods](https://arxiv.org/abs/2308.04734).
- (Nov-23) New paper [*Non-Uniform Smoothness for Gradient Descent*](https://arxiv.org/abs/2311.08615) with [Albert Berahas](https://aberahas.engin.umich.edu/) (University of Michigan) and [Fred Roosta](https://people.smp.uq.edu.au/FredRoosta/) (University of Queensland). We introduce a new local first-order smoothness oracle for automatic tuning of stepsizes for gradient descent.
- (Nov-23) Our paper [*Analyzing Inexact Hypergradients for Bilevel Learning*](https://doi.org/10.1093/imamat/hxad035) with [Matthias Ehrhardt](https://mehrhardt.github.io/) (University of Bath) has been accepted by IMA Journal of Applied Mathematics. 
- (Nov-23) I am on the judging panel for the first SigmaOpt Student Best Paper Prize (for Australian students working in optimization), which will be presented at the [SigmaOpt workshop](https://www.mathematics.org.au/sys/pages/plain.php?page_id=25&conf_id=61) after ANZIAM 2024. See the workshop page for details.
- (Oct-23) I will be an invited speaker at the first [SigmaOpt workshop](https://www.mathematics.org.au/sys/pages/plain.php?page_id=25&conf_id=61) associated with the ANZIAM meeting in February 2024. I am also on the judging panel for the best student paper prize which will be awarded at the workshop. 
- (Oct-23) I gave a One School seminar (i.e. school colloquium) for the USyd School of Mathematics and Statistics.
- (Sep-23) I will be speaking about large-scale DFO at the [Simons Collaboration on Hidden Symmetries and Fusion Energy](https://hiddensymmetries.princeton.edu/meetings/simons-hour-talks).
- (Aug-23) Very excited to receive an [ARC Discovery Early Career Researcher Award](https://www.arc.gov.au/funding-research/funding-schemes/discovery-program/discovery-early-career-researcher-award-decra) (2024-2026). See a short project description on the [ARC page of all funded projects](https://rms.arc.gov.au/RMS/Report/Download/Report/1b0c8b2e-7bb0-4f2d-8f52-ad207cfbb41d/252) or the [university news item](https://www.sydney.edu.au/news-opinion/news/2023/08/28/early-career-researchers-awarded-5-1m-funding.html).
- (Aug-23) New paper [*Dynamic Bilevel Learning with Inexact Line Search*](https://arxiv.org/abs/2308.10098) with [Mohammad Sadegh Salehi](https://mohammadsadeghsalehi.github.io/), [Matthias Ehrhardt](https://mehrhardt.github.io/) (University of Bath) and [Subhadip Mukherjee](https://sites.google.com/view/subhadip-mukherjee/home) (IIT Kharagpur). We introduce a linesearch algorithm suitable for bilevel learning based on conntrollable accuracy function and (hyper)gradient evaluations.
- (Aug-23) New paper [*Expected decrease for derivative-free algorithms using random subspaces*](https://arxiv.org/abs/2308.04734) with [Warren Hare](https://cmps.ok.ubc.ca/about/contact/warren-hare/) (University of British Columbia) and [Clément Royer](https://www.lamsade.dauphine.fr/~croyer/) (Université Paris Dauphine-PSL). We study why random subspace methods work best with very low-dimensional subspaces.
- (Aug-23) Our paper [*Direct search based on probabilistic descent in reduced spaces*](https://doi.org/10.1137/22M1488569) with [Clément Royer](https://www.lamsade.dauphine.fr/~croyer/) (Université Paris Dauphine-PSL) has been accepted by SIAM Journal on Optimization.
- (Jul-23) Our paper [*Mask design, fabrication, and experimental ghost imaging applications for patterned X-ray illumination*](https://doi.org/10.1364/OE.495024) with [Alaleh Aminzadeh](https://physics.anu.edu.au/contact/people/profile.php?ID=2927), [Benjamin Young](https://physics.anu.edu.au/contact/people/profile.php?ID=1150) and [Cheng-I Chiang](https://physics.anu.edu.au/contact/people/profile.php?ID=3077) (ANU), [Imants Svalbe](https://research.monash.edu/en/persons/imants-svalbe) and [David Paganin](https://www.monash.edu/science/schools/physics/research/research-areas?a=64532) (Monash University) and [Andrew Kingston](https://physics.anu.edu.au/contact/people/profile.php?ID=67) (ANU) has been accepted by Optics Express.
- (Jun-23) I will be speaking about [hypergradient estimation for bilevel optimization](https://arxiv.org/abs/2301.04764) at [SIAM Conference on Optimization](https://www.siam.org/conferences/cm/conference/op23) in Seattle, and am co-organising a series of minisymposia on derivative-free optimization with [Clément Royer](https://www.lamsade.dauphine.fr/~croyer/) (Université Paris Dauphine-PSL), [Warren Hare](https://cmps.ok.ubc.ca/about/contact/warren-hare/) (UBC) and [Sébastien Le Digabel](https://www.gerad.ca/Sebastien.Le.Digabel/) (Polytechnique Montréal).
- (May-23) Together with [Geordie Williamson](https://www.maths.usyd.edu.au/u/geordie/) (USyd) I spoke to Associated Press about the role of AI in mathematics, featured for example in the [SBS News in Depth podcast](https://www.sbs.com.au/news/podcast-episode/mathematicians-say-artificial-intelligence-just-doesnt-add-up/jfvzbolc3).
- (May-23) New paper [*Mask design, fabrication, and experimental ghost imaging applications for patterned X-ray illumination*](https://doi.org/10.1364/OE.495024) with [Alaleh Aminzadeh](https://physics.anu.edu.au/contact/people/profile.php?ID=2927), [Benjamin Young](https://physics.anu.edu.au/contact/people/profile.php?ID=1150) and [Cheng-I Chiang](https://physics.anu.edu.au/contact/people/profile.php?ID=3077) (ANU), [Imants Svalbe](https://research.monash.edu/en/persons/imants-svalbe) and [David Paganin](https://www.monash.edu/science/schools/physics/research/research-areas?a=64532) (Monash University) and [Andrew Kingston](https://physics.anu.edu.au/contact/people/profile.php?ID=67) (ANU). This is an experimental follow-up to our previous, more computational [ghost imaging paper](https://dx.doi.org/10.1103/PhysRevA.107.023524). 
- (Feb-23) Our paper [*Optimizing illumination patterns for classical ghost imaging*](https://dx.doi.org/10.1103/PhysRevA.107.023524) with [Andrew Kingston](https://physics.anu.edu.au/contact/people/profile.php?ID=67) and [Alaleh Aminzadeh](https://physics.anu.edu.au/contact/people/profile.php?ID=2927) (ANU), [Daniele Pelliccia](https://www.idtools.com.au/about/) (Instruments and Data Tools Pty Ltd), [Imants Svalbe](https://research.monash.edu/en/persons/imants-svalbe) and [David Paganin](https://www.monash.edu/science/schools/physics/research/research-areas?a=64532) (Monash University) has been accepted by Physical Review A.
- (Jan-23) New paper [*Analyzing Inexact Hypergradients for Bilevel Learning*](https://arxiv.org/abs/2301.04764) with [Matthias Ehrhardt](https://mehrhardt.github.io/) (University of Bath). We look at how to efficiently compute the gradients for bilevel learning using both classical and modern techniques.
- (Dec-22) I will be talking about efficient hypergradient evaluation for bilevel optimisation at the [AustMS Annual Meeting](https://conference.unsw.edu.au/en/austms2022). 
- (Nov-22) I will be giving an overview of black-box optimisation techniques at the [Biarri Applied Mathematics Conference](https://bamconf.com/). My [slides are available here]({{< ref "talk/biarri2022/index.md" >}}).
- (Nov-22) New paper [*On the selection of the weighting parameter value in optimizing Eucalyptus globulus pulp yield models based on NIR spectra*](https://doi.org/10.1007/s00226-022-01431-9) with [Yi Zhen](https://optima.org.au/staff/shiraz-zhen/) (University of Melbourne), and [Tu Ho](https://directory.forestry.oregonstate.edu/people/ho-tu), [Laurence Schimleck](https://directory.forestry.oregonstate.edu/people/schimleck-laurence) and [Arijit Sinha](https://cce.oregonstate.edu/node/532) (Oregon State University) has been accepted by Wood Science and Technology. We study how to select NIR wavelengths for predicting wood yield without overfitting.
- (Nov-22) New paper [*Optimizing illumination patterns for classical ghost imaging*](https://arxiv.org/abs/2211.03792) with [Andrew Kingston](https://physics.anu.edu.au/contact/people/profile.php?ID=67) and [Alaleh Aminzadeh](https://physics.anu.edu.au/contact/people/profile.php?ID=2927) (ANU), [Daniele Pelliccia](https://www.idtools.com.au/about/) (Instruments and Data Tools Pty Ltd), [Imants Svalbe](https://research.monash.edu/en/persons/imants-svalbe) and [David Paganin](https://www.monash.edu/science/schools/physics/research/research-areas?a=64532) (Monash University). We give advice for how to choose/fabricat masks for classical ghost imaging, or - for mathematicians - how to select linear operators to accurately measure objects with linear least-squares regression under practical experimental setups.
- (Oct-22) New paper [*PyCUTEst: an open source Python package of optimization test problems*](https://doi.org/10.21105/joss.04377) with [Jaroslav Fowkes](https://www.scd.stfc.ac.uk/Pages/Fowkes,-Jaroslav.aspx) (Rutherford Appleton Laboratory) and [Árpád Bűrmen](https://www.fe.uni-lj.si/en/the_faculty/staff/associate_professors/55/) (University of Ljubljana) has been accepted by the Journal of Open Source Software. This is a short summary paper outlining the [PyCUTEst](https://github.com/jfowkes/pycutest) software package.
- (Sep-22) I will be speaking about large-scale DFO at the Curtin Centre for Optimisation and Decision Science Colloquium.
- (Aug-22) New paper [*A Simplified Convergence Theory for Byzantine Resilient Stochastic Gradient Descent*](https://doi.org/10.1016/j.ejco.2022.100038) with Edward Smyth (Australian National University) has been accepted by the EURO Journal on Computational Optimization. We significantly simplify existing theory for distributed SGD in the presence of adversarial nodes. 
- (Aug-22) Our paper [*Model-Based Derivative-Free Methods for Convex-Constrained Optimization*](https://doi.org/10.1137/21M1460971) with [Matthew Hough](https://www.math.uwaterloo.ca/~mhough/) (University of Waterloo) has been accepted by SIAM Journal on Optimization. 
- (Jul-22) I will be speaking about large-scale DFO at the [ARC OPTIMA training centre seminar series](https://optima.org.au/events/optima-seminar-series-27-jul-2022/). Update: a recording of the talk is [available on YouTube](https://www.youtube.com/watch?v=fW7a0vVgatw).
- (Jul-22) I am excited to have started a new position as a lecturer in the [School of Mathematics and Statistics](https://www.maths.usyd.edu.au/) at the [University of Sydney](https://www.sydney.edu.au/). 
- (Jun-22) Our paper [*Scalable Subspace Methods for Derivative-Free Nonlinear Least-Squares Optimization*](https://doi.org/10.1007/s10107-022-01836-1) with [Coralia Cartis](http://people.maths.ox.ac.uk/cartis/) (University of Oxford) has been published in Mathematical Programming. 
- (Apr-22) New paper out, [*Direct search based on probabilistic descent in reduced spaces*](https://arxiv.org/abs/2204.01275) with [Clément Royer](https://www.lamsade.dauphine.fr/~croyer/) (Université Paris Dauphine-PSL), showing how using randomized subspaces can make direct search methods more efficient at scale. 
- (Feb-22) Some thoughts I have about giving research seminars are now available on the [ANU MSI website](https://maths.anu.edu.au/files/talk-advice.pdf). They are based on mine and [Pierre Portal's](https://sites.google.com/view/pierre-portal/home) experiences and are aimed at students in any area of mathematics. Of course, they are just our opinions and shouldn't be taken as definitive!
- (Dec-21) Our paper [*Does Model Calibration Reduce Uncertainty in Climate Projections?*](https://doi.org/10.1175/JCLI-D-21-0434.1), led by [Simon Tett](https://www.research.ed.ac.uk/en/persons/simon-tett) (University of Edinburgh) has been accepted to the Journal of Climate. If this isn't your area, perhaps my [brief summary for mathematicians]({{< ref "publication/climate-calibration-uncertainty/index.md" >}}) might help.
- (Dec-21) I will be speaking about [convex-constrained DFO](http://arxiv.org/abs/2111.05443) at [WoMBaT](https://wombat.mocao.org/) and [AustMS 2021](https://austms.org.au/event/austms-2021/).
- (Nov-21) I am lead organizer for the [Workshop on the Intersections of Computation and Optimisation](https://maths.anu.edu.au/news-events/events/workshop-intersections-computation-and-optimisations) on 22-25 November at ANU. This is the first such workshop, a new initiative of the AustMS special interest group [MoCaO](https://www.mocao.org/). 
- (Nov-21) New paper out, [*Model-Based Derivative-Free Methods for Convex-Constrained Optimization*](http://arxiv.org/abs/2111.05443) with [Matthew Hough](https://www.math.uwaterloo.ca/~mhough/) (University of Waterloo), where we show how use interpolation in general convex sets to do model-based derivative-free optimization. You can now download the new version 1.3 of [DFO-LS](https://github.com/numericalalgorithmsgroup/dfols) which can now solve problems with general convex constraints!
- (Oct-21) I will be speaking about large-scale DFO at the [INFORMS Annual Meeting](https://www.informs.org/Meetings-Conferences/INFORMS-Conference-Calendar/2021-INFORMS-Annual-Meeting), as well as organising two sessions on DFO.
- (Oct-21) I will be speaking about bilevel learning at the [Machine Intelligence and Learning Systems](https://www.lamsade.dauphine.fr/wp/miles/) seminar at Université Paris Dauphine-PSL.
- (Sep-21) I will be speaking about large-scale DFO at the University of Leicester's CSE Mathematics Seminar.
- (Jul-21) I will be speaking about large-scale DFO at [EUROPT](https://europt2021.sciencesconf.org/), [EURO](https://euro2021athens.com/) and [SIOPT](https://www.siam.org/conferences/cm/conference/op21).
- (Jul-21) I was [interviewed by Channel 9 National News](https://www.youtube.com/watch?v=9CHHjuBWOXs) about projections for Australia's COVID-19 vaccine rollout.
- (Jun-21) Delighted to be announced as the first prize winner of the [20th IMA Leslie Fox Prize for Numerical Analysis](https://ima.org.uk/awards-medals/ima-leslie-fox-prize-numerical-analysis/) for my recent paper on [scalable DFO](https://arxiv.org/abs/2102.12016)! You can [watch my talk on YouTube](https://www.youtube.com/watch?v=CS2QBTwR8-4).
- (Jun-21) New paper submitted, *Does Model Calibration Reduce Uncertainty in Climate Projections?*, led by [Simon Tett](https://www.research.ed.ac.uk/en/persons/simon-tett) (University of Edinburgh). The study shows that performing structured parameter tuning of climate models helps to significantly reduce the uncertainties in their predictions. It also shows that my [DFO-LS](https://github.com/numericalalgorithmsgroup/dfols) code is an effective solver for parameter fitting of climate models. Preprint coming soon!
- (May-21) Very happy to be shortlisted for the [IMA Leslie Fox Prize for Numerical Analysis](https://ima.org.uk/awards-medals/ima-leslie-fox-prize-numerical-analysis/) for my recent paper on [scalable DFO](https://arxiv.org/abs/2102.12016). I will be talking about my work at the [Fox Prize event on 21 June](https://ima.org.uk/16899/20th-ima-leslie-fox-prize-event/).
- (Apr-21) Excited to be interviewed by Channel 9 National News about the progress of Australia's COVID-19 vaccine rollout on [1 April](https://youtube.com/watch?v=OfWOTrvRFHg) and [16 April](https://www.youtube.com/watch?v=puN9aKbcvys).
- (Mar-21) I will be speaking about bilevel learning at [SIAM CSE](https://www.siam.org/conferences/cm/conference/cse21).
- (Feb-21) New paper [*Scalable Subspace Methods for Derivative-Free Nonlinear Least-Squares Optimization*](https://arxiv.org/abs/2102.12016) with [Coralia Cartis](http://people.maths.ox.ac.uk/cartis/) (University of Oxford). This introduces a general framework for derivative-free optimization in random subspaces and specializes it to nonlinear least-squares problems (with an [efficient implementation](https://github.com/numericalalgorithmsgroup/dfbgn)). 
- (Jan-21) My paper [*Escaping local minima with local derivative-free methods*](https://doi.org/10.1080/02331934.2021.1883015) with [Coralia Cartis](http://people.maths.ox.ac.uk/cartis/) and [Oliver Sheridan-Methven](https://www.maths.ox.ac.uk/people/oliver.sheridan-methven) (University of Oxford) has been accepted by *Optimization*.
- (Dec-20) My paper [*Inexact Derivative-Free Optimization for Bilevel Learning*](https://doi.org/10.1007/s10851-021-01020-8) with [Matthias Ehrhardt](https://mehrhardt.github.io/) (University of Bath) has been accepted by the *Journal of Mathematical Imaging and Vision*.
- (Dec-20) I will be speaking about large-scale DFO methods at both [WoMBaT](https://wombat.mocao.org/) and the optimization stream of [AustMS](https://austms.org.au/meetings/annual-conferences/2020-austms-meeting/). 
- (Nov-20) New paper [*Efficient Hyperparameter Tuning with Dynamic Accuracy Derivative-Free Optimization*](https://arxiv.org/abs/2011.03151) with [Matthias Ehrhardt](https://mehrhardt.github.io/) (University of Bath) has been accepted for the [OPT2020 workshop](http://www.opt-ml.org/) at NeurIPS 2020. We introduce an efficient hyperparameter tuning algorithm with convergence guarantees.
- (Oct-20) I'm delighted to receive the Reddick Prize from the [InFoMM CDT](https://www.maths.ox.ac.uk/study-here/postgraduate-study/industrially-focused-mathematical-modelling-epsrc-cdt) at the University of Oxford for my doctoral research! Read more [here](https://maths.anu.edu.au/news-events/news/lindon-roberts-awarded-prestigious-reddick-prize-university-oxford).
- (Oct-20) New software package [DFBGN](https://github.com/numericalalgorithmsgroup/dfbgn) is now available. It solves large-scale nonlinear least-squares problems without derivatives. 
- (Jun-20) New paper [*Scalable Derivative-Free Optimization for Nonlinear Least-Squares Problems*](https://arxiv.org/abs/2007.13243) with [Coralia Cartis](http://people.maths.ox.ac.uk/cartis/) and Tyler Ferguson (Oxford) has been accepted for the ICML workshop [Beyond First-Order Methods in ML Systems](https://sites.google.com/view/optml-icml2020/accepted-papers).
- (Jun-20) New paper [*Inexact Derivative-Free Optimization for Bilevel Learning*](https://arxiv.org/abs/2006.12674) with [Matthias Ehrhardt](https://mehrhardt.github.io/) (University of Bath)! We introduce a new algorithm for learning variational regularization parameters, applicable to problems such as image denoising and MRI reconstruction.
- (May-20) My [nonlinear optimization resources](opt/) page is now public. This has been built over several years with [Coralia Cartis](http://people.maths.ox.ac.uk/cartis/) (University of Oxford) and [Jaroslav Fowkes](https://www.scd.stfc.ac.uk/Pages/Fowkes,-Jaroslav.aspx) (STFC Rutherford Appleton Laboratory).
- (Apr-20) I will be (virtually) presenting at the [UNSW Applied Mathematics Seminar](https://www.maths.unsw.edu.au/seminars/2020-04/derivative-free-optimisation-least-squares-problems). It will be recorded, so email me if you want to watch the recording.
- (Feb-20) My paper [*A derivative-free Gauss-Newton method*](https://doi.org/10.1007/s12532-019-00161-7) has been awarded the [best paper of 2019](https://www.springer.com/journal/12532/updates/17226372) for the journal *Mathematical Programming Computation*! 
- (Jan-20) I will be attending the [Mathematics in Industry Study Group](https://mathsinindustry.com/) at the University of Newcastle.
- (Dec-19) I will be presenting at the first [Data Science Down Under](https://carma.newcastle.edu.au/meetings/dsdu/) workshop at the University of Newcastle.
- (Nov-19) I will be an invited speaker at ANU's [Uncertainty Quantification workshop](https://maths.anu.edu.au/news-events/events/uncertainty-quantification-workshop).
