---
# Display name
name: Lindon Roberts

# Username (this should match the folder name)
authors:
- admin

# Is this the primary user of the site?
superuser: true

# Role/position
role: Lecturer

# Organizations/Affiliations
organizations:
- name: University of Sydney
  url: ""

# Short bio (displayed in user profile at end of posts)
bio: My research is in numerical analysis and data science, particularly nonconvex and derivative-free optimization.

interests:
- Derivative-Free Optimization
- Nonconvex Optimization
- Numerical Analysis
- Data Science

education:
  courses:
  - course: DPhil in Mathematics
    institution: University of Oxford
    year: 2019
  - course: Bachelor of Computational Science (Honours)
    institution: Australian National University
    year: 2011

# Social/Academic Networking
# For available icons, see: https://sourcethemes.com/academic/docs/widgets/#icons
#   For an email link, use "fas" icon pack, "envelope" icon, and a link in the
#   form "mailto:your-email@example.com" or "#contact" for contact widget.
social:
- icon: envelope
  icon_pack: fas
  link: 'mailto:lindon.roberts@sydney.edu.au'  # Was '#contact'. For a direct email link, use "mailto:test@example.org".
- icon: google-scholar
  icon_pack: ai
  link: https://scholar.google.co.uk/citations?user=s8Xj5BgAAAAJ
- icon: github
  icon_pack: fab
  link: https://github.com/lindonroberts
# Link to a PDF of your resume/CV from the About widget.
# To enable, copy your resume/CV to `static/files/cv.pdf` and uncomment the lines below.  
# - icon: cv
#   icon_pack: ai
#   link: files/cv.pdf

# Enter email to display Gravatar (if Gravatar enabled in Config)
email: "lindon.roberts@sydney.edu.au"
  
# Organizational groups that you belong to (for People widget)
#   Set this to `[]` or comment out if you are not using People widget.  
#user_groups:
#- Researchers
#- Visitors
---

I am a lecturer and ARC DECRA Fellow at the School of Mathematics and Statistics, University of Sydney. My research interests are in numerical analysis and data science, particularly nonconvex and derivative-free optimization. 

Details of my CV, publications, talks and software are below (or look at [Google Scholar](https://scholar.google.co.uk/citations?user=s8Xj5BgAAAAJ) and [Github](https://github.com/lindonroberts)). For general optimization resources, see below or my [nonlinear optimization resources](opt/) page.

**Recent news:**

- (Jan-25) New paper [*Projected proximal gradient trust-region algorithm for nonsmooth optimization*](https://arxiv.org/abs/2501.04889) with [Minh Dao](https://sites.google.com/site/daonminh/) (RMIT University) and [Hung Phan](https://faculty.uml.edu/hung_phan/) (University of Massachusetts Lowell). We develop some new worst-case complexity theory and novel subproblem solver for trust-region methods with nonsmooth regularizers.
- (Dec-24) New paper [*Randomized Subspace Derivative-Free Optimization with Quadratic Models and Second-Order Convergence*](https://arxiv.org/abs/2412.14431) with [Coralia Cartis](http://people.maths.ox.ac.uk/cartis/) (University of Oxford). We extend the theory of random subspace derivative-free optimization to include second-order complexity and develop a practical algorithm based on quadratic interpolation models.
- (Dec-24) New paper [*Bilevel Learning with Inexact Stochastic Gradients*](https://arxiv.org/abs/2412.12049) with [Mohammad Sadegh Salehi](https://mohammadsadeghsalehi.github.io/), [Matthias Ehrhardt](https://mehrhardt.github.io/) (University of Bath) and [Subhadip Mukherjee](https://sites.google.com/view/subhadip-mukherjee/home) (IIT Kharagpur). We show how the theory of biased SGD can be applied to bilevel learning with inexact hypergradients.
- (Dec-24) I will be presenting on [convex-constrained derivative-free optimization](https://arxiv.org/abs/2403.14960) at [WOMBAT 2024](https://wombat.mocao.org/) and [adaptive bilevel learning](https://arxiv.org/abs/2308.10098) at the [Sydney Workshop on the Mathematics of Data Science](https://www.maths.usyd.edu.au/u/USYD-MDSworkshop/), both running at the University of Sydney.
- (Nov-24) Excited to receive an Australian Research Council [Discovery Project 2025](https://www.arc.gov.au/funding-research/grant-announcement-kits/discovery-projects-2025) grant for the project *Next Generation Newton-type Methods with Minimum Residual Solver*, with [Fred Roosta](https://people.smp.uq.edu.au/FredRoosta/) (University of Queensland), [Andre Milzarek](https://sds.cuhk.edu.cn/en/teacher/64) (Chinese University of Hong Kong, Shenzhen) and [Steve Wright](https://wrightstephen.github.io/sw_proj/) (University of Wisconsin-Madison).
- (Oct-24) New paper [*High-resolution x-ray scanning with a diffuse, Huffman-patterned probe to minimise radiation damage*](https://arxiv.org/abs/2410.18348) with [Alaleh Aminzadeh](https://physics.anu.edu.au/contact/people/profile.php?ID=2927) and [Andrew Kingston](https://physics.anu.edu.au/contact/people/profile.php?ID=67) (ANU), and
[David Paganin](https://www.monash.edu/science/schools/physics/research/research-areas?a=64532), [Tim Petersen](https://research.monash.edu/en/persons/timothy-petersen) and [Imants Svalbe](https://monash.academia.edu/ImantsSvalbe)  (Monash University). We demonstrate how to computationally construct aperiodic masks for ghost imaging and show their practical experimental performance.
- (Sep-24) I will be talking about randomized subspace derivative-free optimization algorithms at the [UNSW Applied Mathematics Seminar](https://www.unsw.edu.au/science/our-schools/maths/engage-with-us/seminars/2024/Randomised-Subspace-Methods-for-Scalable-Derivative-Free-Optimisation). 
- (Aug-24) Our paper [*Expected decrease for derivative-free algorithms using random subspaces*](https://doi.org/10.1090/mcom/4011) with [Warren Hare](https://cmps.ok.ubc.ca/about/contact/warren-hare/) (University of British Columbia) and [Clément Royer](https://www.lamsade.dauphine.fr/~croyer/) (Université Paris Dauphine-PSL) has been accepted by Mathematics of Computation.

[Click here for older news]({{< ref "news/archive.md" >}})

**Awards:**

- [ARC DECRA fellowship](https://www.arc.gov.au/funding-research/funding-schemes/discovery-program/discovery-early-career-researcher-award-decra) (2024-2026).
- [IMA Leslie Fox Prize for Numerical Analysis](https://ima.org.uk/awards-medals/ima-leslie-fox-prize-numerical-analysis/) (2021).
- Reddick Prize, Mathematical Institute, University of Oxford (2020).
- [Best paper award, *Mathematical Programming Computation*](https://www.springer.com/journal/12532/updates/17226372) (2019).