---
# Display name
name: Lindon Roberts

# Username (this should match the folder name)
authors:
- admin

# Is this the primary user of the site?
superuser: true

# Role/position
role: Lecturer

# Organizations/Affiliations
organizations:
- name: University of Sydney
  url: ""

# Short bio (displayed in user profile at end of posts)
bio: My research is in numerical analysis, particularly nonconvex and derivative-free optimization.

interests:
- Derivative-Free Optimization
- Nonconvex Optimization
- Numerical Analysis
- Data Science

education:
  courses:
  - course: DPhil in Mathematics
    institution: University of Oxford
    year: 2019
  - course: Bachelor of Computational Science (Honours)
    institution: Australian National University
    year: 2011

# Social/Academic Networking
# For available icons, see: https://sourcethemes.com/academic/docs/widgets/#icons
#   For an email link, use "fas" icon pack, "envelope" icon, and a link in the
#   form "mailto:your-email@example.com" or "#contact" for contact widget.
social:
- icon: envelope
  icon_pack: fas
  link: 'mailto:lindon.roberts@sydney.edu.au'  # Was '#contact'. For a direct email link, use "mailto:test@example.org".
- icon: google-scholar
  icon_pack: ai
  link: https://scholar.google.co.uk/citations?user=s8Xj5BgAAAAJ
- icon: github
  icon_pack: fab
  link: https://github.com/lindonroberts
# Link to a PDF of your resume/CV from the About widget.
# To enable, copy your resume/CV to `static/files/cv.pdf` and uncomment the lines below.  
# - icon: cv
#   icon_pack: ai
#   link: files/cv.pdf

# Enter email to display Gravatar (if Gravatar enabled in Config)
email: "lindon.roberts@sydney.edu.au"
  
# Organizational groups that you belong to (for People widget)
#   Set this to `[]` or comment out if you are not using People widget.  
#user_groups:
#- Researchers
#- Visitors
---

I am a lecturer at the School of Mathematics and Statistics, University of Sydney. My research interests are in numerical analysis and data science, particularly nonconvex and derivative-free optimization. 

Details of my CV, publications, talks and software are below (or look at [Google Scholar](https://scholar.google.co.uk/citations?user=s8Xj5BgAAAAJ) and [Github](https://github.com/lindonroberts)). For general optimization resources, see below or my [nonlinear optimization resources](opt/) page.

**Recent news:**

- (Jan-23) New paper [*Analyzing Inexact Hypergradients for Bilevel Learning*](https://arxiv.org/abs/2301.04764) with [Matthias Ehrhardt](https://mehrhardt.github.io/) (University of Bath). We look at how to efficiently compute the gradients for bilevel learning using both classical and modern techniques.
- (Dec-22) I will be talking about efficient hypergradient evaluation for bilevel optimisation at the [AustMS Annual Meeting](https://conference.unsw.edu.au/en/austms2022). 
- (Nov-22) I will be giving an overview of black-box optimisation techniques at the [Biarri Applied Mathematics Conference](https://bamconf.com/). My [slides are available here]({{< ref "talk/biarri2022/index.md" >}}).
- (Nov-22) New paper [*On the selection of the weighting parameter value in optimizing Eucalyptus globulus pulp yield models based on NIR spectra*](https://doi.org/10.1007/s00226-022-01431-9) with [Yi Zhen](https://optima.org.au/staff/shiraz-zhen/) (University of Melbourne), and [Tu Ho](https://directory.forestry.oregonstate.edu/people/ho-tu), [Laurence Schimleck](https://directory.forestry.oregonstate.edu/people/schimleck-laurence) and [Arijit Sinha](https://cce.oregonstate.edu/node/532) (Oregon State University) has been accepted by Wood Science and Technology. We study how to select NIR wavelengths for predicting wood yield without overfitting.
- (Nov-22) New paper [*Optimizing illumination patterns for classical ghost imaging*](https://arxiv.org/abs/2211.03792) with [Andrew Kingston](https://physics.anu.edu.au/contact/people/profile.php?ID=67) and [Alaleh Aminzadeh](https://physics.anu.edu.au/contact/people/profile.php?ID=2927) (ANU), [Daniele Pelliccia](https://www.idtools.com.au/about/) (Instruments and Data Tools Pty Ltd), [Imants Svalbe](https://research.monash.edu/en/persons/imants-svalbe) and [David Paganin](https://www.monash.edu/science/schools/physics/research/research-areas?a=64532) (Monash University). We give advice for how to choose/fabricate masks for classical ghost imaging, or - for mathematicians - how to select linear operators to accurately measure objects with linear least-squares regression under practical experimental setups.
- (Oct-22) New paper [*PyCUTEst: an open source Python package of optimization test problems*](https://doi.org/10.21105/joss.04377) with [Jaroslav Fowkes](https://www.scd.stfc.ac.uk/Pages/Fowkes,-Jaroslav.aspx) (Rutherford Appleton Laboratory) and [Árpád Bűrmen](https://www.fe.uni-lj.si/en/the_faculty/staff/associate_professors/55/) (University of Ljubljana) has been accepted by the Journal of Open Source Software. This is a short summary paper outlining the [PyCUTEst](https://github.com/jfowkes/pycutest) software package.
- (Sep-22) I will be speaking about large-scale DFO at the Curtin Centre for Optimisation and Decision Science Colloquium.
- (Aug-22) New paper [*A Simplified Convergence Theory for Byzantine Resilient Stochastic Gradient Descent*](https://doi.org/10.1016/j.ejco.2022.100038) with Edward Smyth (Australian National University) has been accepted by the EURO Journal on Computational Optimization. We significantly simplify existing theory for distributed SGD in the presence of adversarial nodes. 
- (Aug-22) Our paper [*Model-Based Derivative-Free Methods for Convex-Constrained Optimization*](https://doi.org/10.1137/21M1460971) with [Matthew Hough](https://www.math.uwaterloo.ca/~mhough/) (University of Waterloo) has been accepted by SIAM Journal on Optimization. 
- (Jul-22) I will be speaking about large-scale DFO at the [ARC OPTIMA training centre seminar series](https://optima.org.au/events/optima-seminar-series-27-jul-2022/). Update: a recording of the talk is [available on YouTube](https://www.youtube.com/watch?v=fW7a0vVgatw).
- (Jul-22) I am excited to have started a new position as a lecturer in the [School of Mathematics and Statistics](https://www.maths.usyd.edu.au/) at the [University of Sydney](https://www.sydney.edu.au/). 
- (Jun-22) Our paper [*Scalable Subspace Methods for Derivative-Free Nonlinear Least-Squares Optimization*](https://doi.org/10.1007/s10107-022-01836-1) with [Coralia Cartis](http://people.maths.ox.ac.uk/cartis/) (University of Oxford) has been published in Mathematical Programming. 
- (Apr-22) New paper out, [*Direct search based on probabilistic descent in reduced spaces*](https://arxiv.org/abs/2204.01275) with [Clément Royer](https://www.lamsade.dauphine.fr/~croyer/) (Université Paris Dauphine-PSL), showing how using randomized subspaces can make direct search methods more efficient at scale. 

[News archive]({{< ref "news/archive.md" >}})

**Awards:**

- [IMA Leslie Fox Prize for Numerical Analysis](https://ima.org.uk/awards-medals/ima-leslie-fox-prize-numerical-analysis/) (2021).
- Reddick Prize, Mathematical Institute, University of Oxford (2020).
- [Best paper award, *Mathematical Programming Computation*](https://www.springer.com/journal/12532/updates/17226372) (2019).